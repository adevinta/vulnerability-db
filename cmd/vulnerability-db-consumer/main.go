/*
Copyright 2020 Adevinta
*/

package main

import (
	"context"
	"flag"
	"fmt"
	"os"
	"sync"

	"github.com/adevinta/vulnerability-db/pkg/asyncapi/kafka"
	"github.com/adevinta/vulnerability-db/pkg/maintenance"
	"github.com/adevinta/vulnerability-db/pkg/notify"
	"github.com/adevinta/vulnerability-db/pkg/processor"
	"github.com/adevinta/vulnerability-db/pkg/queue"
	"github.com/adevinta/vulnerability-db/pkg/results"
	"github.com/adevinta/vulnerability-db/pkg/store"
	log "github.com/sirupsen/logrus"
)

func main() {

	// Read config.
	cfgFilePath := flag.String("c", "./config.toml", "configuration file")
	flag.Parse()

	conf, err := parseConfig(*cfgFilePath)
	if err != nil {
		log.Fatalf("Error reading configuration: %v", err)
	}

	logger := setupLogger(*conf)

	// Build store.
	cs := conf.DB
	connStr := fmt.Sprintf("host=%s port=%s user=%s password=%s dbname=%s sslmode=%s",
		cs.Host, cs.Port, cs.User, cs.Pass, cs.Name, cs.SSLMode)
	db, err := store.NewDB(connStr, logger)
	if err != nil {
		log.Fatalf("Error connecting to DB: %v", err)
	}

	// Build notifier.
	notifier, err := buildNotifier(conf, logger)
	if err != nil {
		log.Fatalf("Error building notifier: %v", err)
	}

	// Build processor.
	resultsClient, err := results.NewClient(logger)
	if err != nil {
		log.Fatalf("Error creating results client: %v", err)
	}

	processor, err := processor.NewCheckProcessor(notifier, db, resultsClient, conf.Report.URLReplace, conf.MaxEventAge, logger)
	if err != nil {
		log.Fatalf("Error creating queue processor: %v", err)
	}

	// Build consumer group.
	sqsConf := queue.SQSConfig{
		QueueArn:    conf.SQS.QueueARN,
		Timeout:     int64(conf.SQS.Timeout),
		MaxWaitTime: int64(conf.SQS.WaitTime),
		Endpoint:    conf.SQS.Endpoint,
	}
	sqsConsumerGroup, err := queue.NewSQSConsumerGroup(conf.SQS.NProcessors, sqsConf, processor, logger)
	if err != nil {
		log.Fatalf("Error creating queue consumer group: %v", err)
	}

	// Build and start maintenance scheduler.
	scheduler := maintenance.NewScheduler(logger, []maintenance.TaskSchedule{})
	for _, taskConfig := range conf.Maintenance.Tasks {
		t, err := maintenance.NewTask(taskConfig.Name, taskConfig.Type, taskConfig.Options, db)
		if err != nil {
			log.Fatalf("Error creating maintenance task %s: %v", taskConfig.Name, err)
		}
		err = scheduler.AddTask(t, taskConfig.Rate)
		if err != nil {
			log.Fatalf("Error scheduling maintenance task %s: %v", taskConfig.Name, err)
		}
	}
	scheduler.Start(context.Background())

	// Start consumer.
	var wg sync.WaitGroup
	sqsConsumerGroup.Start(context.Background(), &wg)
	log.Info("Started")
	wg.Wait()
}

// buildNotifier builds the appropiate notifier given the defined configuration.
// TODO: Once the integrations dependent on the old notification format have been
// deprecated or updated to comply with the new format through Kafka topic channel
// we can get rid of SNS and multi implementations of notifier and just use Kafka.
func buildNotifier(conf *config, logger *log.Logger) (notify.Notifier, error) {
	if !conf.SNS.Enabled && !conf.Kafka.Enabled {
		return notify.NewNoopNotifier(), nil
	}
	if conf.SNS.Enabled && !conf.Kafka.Enabled {
		return buildSNSNotifier(conf, logger)
	}
	if !conf.SNS.Enabled && conf.Kafka.Enabled {
		return buildKafkaNotifier(conf, logger)
	}
	// Multi Notifier
	k, err := buildKafkaNotifier(conf, logger)
	if err != nil {
		return nil, err
	}
	s, err := buildSNSNotifier(conf, logger)
	if err != nil {
		return nil, err
	}
	return notify.NewMultiNotifier(k, s), nil
}

func buildSNSNotifier(conf *config, logger *log.Logger) (*notify.SNSNotifier, error) {
	return notify.NewSNSNotifier(notify.SNSConfig{
		TopicArn: conf.SNS.TopicARN,
		Endpoint: conf.SNS.Endpoint,
	}, logger)
}

func buildKafkaNotifier(conf *config, logger *log.Logger) (*notify.KafkaNotifier, error) {
	kafkaCli, err := kafka.NewClient(conf.Kafka.User, conf.Kafka.Pass,
		conf.Kafka.BrokerURL, conf.Kafka.Topic)
	if err != nil {
		return nil, err
	}
	return notify.NewKafkaNotifier(kafkaCli, logger), nil
}

func setupLogger(cfg config) *log.Logger {
	var logger = log.New()

	logger.SetFormatter(&log.JSONFormatter{})
	logger.SetOutput(os.Stdout)
	logger.SetLevel(parseLogLevel(cfg.Log.Level))

	return logger
}
